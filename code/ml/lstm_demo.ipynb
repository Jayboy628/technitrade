{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a31824d-e031-4964-9f83-c716c9db3307",
   "metadata": {},
   "source": [
    "![header](../../img/logo.svg)\n",
    "\n",
    "**LSTM Machine Learning Model Demo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fdfbd3-4840-4e4d-b9d1-88a8c698a0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System libraries\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "# Data processing and visulization libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Neural Network library\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Technials Analysis library\n",
    "os.chdir(\"../technicals\")\n",
    "import technicals\n",
    "\n",
    "# Market data connection library\n",
    "os.chdir(\"../marketdata\")\n",
    "import alpaca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b145652-7cc7-4926-833c-d81333f09210",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b758091b-f4f9-428e-b076-7461c563b0e6",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df74172-d913-4d61-8066-eba0ecaec471",
   "metadata": {},
   "source": [
    "### *Market Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff9f2a-2c7a-4e5c-ad54-235d8d466136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set market data date range \n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "end_date  = datetime.now()\n",
    "start_date  = (end_date - timedelta(days=1000))\n",
    "\n",
    "start_date = start_date.strftime('%Y-%m-%d')\n",
    "end_date = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"Start date : {start_date}\")\n",
    "print(f\"End date : {end_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2596af5a-6450-4cf9-8d71-2aa003dc60d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "test_tickers = [\"KO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32cef3d-99c0-4d21-a9b9-1e3d0cad00fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv_df = alpaca.ohlcv(test_tickers, start_date=start_date, end_date=end_date)\n",
    "tech_ind = technicals.TechnicalAnalysis(ohlcv_df)\n",
    "\n",
    "df = tech_ind.get_all_technicals(test_tickers[0])\n",
    "df.drop(columns=['open', 'high', 'low', 'volume'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465050a6-b815-46dd-8c7f-605233e6c546",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa23a07f-ac13-40b1-860b-3c0f825b8179",
   "metadata": {},
   "source": [
    "### *Data pre-processing : Scaling*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7f89a1-643a-43e2-9cac-0d87df055ce1",
   "metadata": {},
   "source": [
    "#### Scaling using [RobustScaler()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html):\n",
    "\n",
    "Scale features using statistics that are robust to outliers.\n",
    "\n",
    "This Scaler removes the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range). The IQR is the range between the 1st quartile (25th quantile) and the 3rd quartile (75th quantile).\n",
    "\n",
    "Centering and scaling happen independently on each feature by computing the relevant statistics on the samples in the training set. Median and interquartile range are then stored to be used on later data using the transform method.\n",
    "\n",
    "Standardization of a dataset is a common requirement for many machine learning estimators. Typically this is done by removing the mean and scaling to unit variance. However, outliers can often influence the sample mean / variance in a negative way. In such cases, the median and the interquartile range often give better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eabe0a-66ec-4314-a5ff-6a63a83a2c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale fitting the close prices separately for inverse_transformations purposes later\n",
    "close_scaler = RobustScaler()\n",
    "close_scaler.fit(df[['close']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9236d170-6d2b-43f3-a562-833435b6d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd9d36f-c331-4a1c-bbbe-85fec7772966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a693ae0b-7f06-4c52-a192-16de04d71f4b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf998057-1f84-45ef-bcab-daa7cec88fd6",
   "metadata": {},
   "source": [
    "### *LSTM Model Helper Functions*\n",
    "\n",
    "1. split_sequence() - splits multivariate time sequences for LSTM training\n",
    "2. add_hidded_layers() - adds requested number of LSTM hidden layers with requested number of nodes\n",
    "3. validater() - validates training results\n",
    "4. rmse() - returns root-mean-squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0068391a-31b3-484b-8c4b-2872713001e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Helper Functions\n",
    "def split_sequence(sequence, n_in, n_out):\n",
    "    '''\n",
    "    Splits the multivariate time sequence\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sequence : np.array\n",
    "        numpy array of the dataframe used to train the model\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X, y : np.array\n",
    "        Time sequence values for X and y portions of the dataset\n",
    "    '''\n",
    "    \n",
    "    # creating a list for both variables\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(sequence)):\n",
    "        \n",
    "        # finding the end of the current sequence\n",
    "        end = i + n_in\n",
    "        out_end = end + n_out\n",
    "        \n",
    "        # breaking out of the loop if we have exceeded the dataset's length\n",
    "        if out_end > len(sequence):\n",
    "            break\n",
    "        \n",
    "        # splitting the sequences into: x = past prices and indicators, y = prices ahead\n",
    "        sequence_x, sequence_y = sequence[i:end, :], sequence[end:out_end, 0]\n",
    "        \n",
    "        X.append(sequence_x)\n",
    "        y.append(sequence_y)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "    \n",
    "    \n",
    "def add_hidden_layers(n_layers, n_nodes, activation, drop=None, drop_rate=.5):\n",
    "    '''\n",
    "    Creates a specific amount of hidden layers for the model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_layers : int\n",
    "        number of layers to be added to the model\n",
    "\n",
    "    n_nodes : int\n",
    "        number of nodes to be added to each layer\n",
    "\n",
    "    activation : str\n",
    "        activation function used by each layers in the model\n",
    "        Full list of all activation functions: \n",
    "            https://www.tensorflow.org/api_docs/python/tf/keras/activations\n",
    "\n",
    "    drop : int\n",
    "        every n-th hidden layer after which a Dropout layer to be added\n",
    "\n",
    "    drop_rate : float\n",
    "        rate for each Dropout layer\n",
    "        default = 0.5\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # creating the specified number of hidden layers with the specified number of nodes\n",
    "    for x in range(1,n_layers+1):\n",
    "        model.add(LSTM(n_nodes, activation=activation, return_sequences=True))\n",
    "\n",
    "        # adds a Dropout layer after every n-th hidden layer\n",
    "        try:\n",
    "            if x % drop == 0:\n",
    "                model.add(Dropout(drop_rate))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    \n",
    "def validater():\n",
    "    '''\n",
    "    Creates predicted values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    predictions : pd.DataFrame\n",
    "        Predicted values for the model\n",
    "    '''\n",
    "    \n",
    "    # Creating an empty DF to store the predictions\n",
    "    predictions = pd.DataFrame(index=df.index, columns=[df.columns[0]])\n",
    "\n",
    "    for i in range(n_in, len(df)-n_in, n_out):\n",
    "        # Creating rolling intervals to predict off of\n",
    "        x = df[-i - n_in:-i]\n",
    "\n",
    "        # Predicting using rolling intervals\n",
    "        y_pred = model.predict(np.array(x).reshape(1, n_in, n_features))\n",
    "\n",
    "        # Transforming values back to their normal prices\n",
    "        y_pred = close_scaler.inverse_transform(y_pred)[0]\n",
    "\n",
    "        # DF to store the values and append later, frequency uses business days\n",
    "        pred_df = pd.DataFrame(y_pred, \n",
    "                               index=pd.date_range(start=x.index[-1], \n",
    "                                                   periods=len(y_pred), \n",
    "                                                   freq=\"B\"),\n",
    "                               columns=[x.columns[0]])\n",
    "\n",
    "        # Updating the predictions DF\n",
    "        predictions.update(pred_df)\n",
    "        \n",
    "    return predictions\n",
    "\n",
    "\n",
    "def rmse(df_actual, df_predicted):\n",
    "    '''\n",
    "    Calculates the RMS (root mean square) error between the two pd.Dataframes\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_actual : pd.DataFrame\n",
    "        DataFrame with Actual Closing prices\n",
    "    df_predicted : pd.DataFrame\n",
    "        DataFrame with Predicted Closing prices\n",
    "    \n",
    "    '''\n",
    "    df = df_actual.copy()\n",
    "    df['close_pred'] = df_predicted['close']\n",
    "    df.dropna(inplace=True)\n",
    "    df['diff'] = df['close']- df['close_pred']\n",
    "    rms = (df[['diff']]**2).mean()\n",
    "    error = float(np.sqrt(rms))\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06f1cc1-e4b3-420f-85c5-963781216016",
   "metadata": {},
   "source": [
    "### *LSTM Visualization Functions*\n",
    "\n",
    "1. visualize_training_results() - plots validation loss, loss, validation accuracy, and accuracy\n",
    "2. visualize_training_price() - plots actual and predicted Closing stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6413c64-d297-4615-8551-8e74a7e134d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_results(results, model_loss_filename : str, model_accuracy_filename : str):\n",
    "    \"\"\"\n",
    "    Plots the loss and accuracy for the training and testing data\n",
    "    \"\"\"\n",
    "    history = results.history\n",
    "    plt.figure(figsize=(16,5))\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.plot(history['loss'])\n",
    "    plt.legend(['val_loss', 'loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.savefig(model_loss_filename)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(16,5))\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.legend(['val_accuracy', 'accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.savefig(model_accuracy_filename)\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_training_price(filename):\n",
    "    '''\n",
    "    Visualizes Actual vs. Predicted stock price\n",
    "    '''\n",
    "\n",
    "    # Transforming the actual values to their original price\n",
    "    actual = pd.DataFrame(close_scaler.inverse_transform(df[[\"close\"]]), \n",
    "                          index=df.index, \n",
    "                          columns=[df.columns[0]])\n",
    "\n",
    "    # Getting a DF of the predicted values to validate against\n",
    "    predictions = validater()\n",
    "\n",
    "    # Printing the RMSE\n",
    "    print(f\"RMSE: {rmse(actual, predictions)}\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(16,6))\n",
    "\n",
    "    # Plotting those predictions\n",
    "    plt.plot(predictions, label='Predicted')\n",
    "\n",
    "    # Plotting the actual values\n",
    "    plt.plot(actual, label='Actual')\n",
    "\n",
    "    plt.title(f\"Predicted vs Actual Closing Prices\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94abb56d-fe79-41a6-81d6-d2d218887c04",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28cd02c-6272-462c-b6de-55bbd6c4b6f5",
   "metadata": {},
   "source": [
    "### *Building LSTM Model*\n",
    "\n",
    "Builds an LSMT model, compiles and fits it.\n",
    "\n",
    "* Looks back 100 days to predict 14 days\n",
    "* Sequential() model - groups a linear stack of layers into a [tf.keras.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model) : [tf.keras.Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)\n",
    "* Uses Hyperbolic tangent activation function : [tf.keras.activations.tanh](https://www.tensorflow.org/api_docs/python/tf/keras/activations/tanh)\n",
    "* Composed of LSTM input and hidden layers - Long Short-Term Memory layer - [Hochreiter 1997](https://dl.acm.org/doi/10.1162/neco.1997.9.8.1735): [tf.keras.layers.LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)\n",
    "* Uses Adam optimzer - a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments : [tf.keras.optimizers.Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam)\n",
    "* Uses Mean Squared Error loss function - computes the mean of squares of errors between labels and predictions: [tf.keras.losses.MeanSquaredError](https://www.tensorflow.org/api_docs/python/tf/keras/losses/MeanSquaredError)\n",
    "* Model is trained for 50 epochs using 128 unit batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c106b1-0783-4912-be0c-d0120885e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n periods looking back to learn\n",
    "n_in  = 100\n",
    "\n",
    "# n periods to predict\n",
    "n_out = 14\n",
    "\n",
    "# n features \n",
    "n_features = df.shape[1]\n",
    "\n",
    "# X, y split\n",
    "X, y = split_sequence(df.to_numpy(), n_in, n_out)\n",
    "\n",
    "# Dataframe for predictions\n",
    "predictions = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57403c0-5f66-4292-82e1-d9ba90388a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instatiating the model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201872e3-009e-405b-a3ad-2fca5b72ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation\n",
    "activation_func = \"tanh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e5979-cf12-42eb-a1be-9bf89eafe63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add input layer\n",
    "model.add(LSTM(90, \n",
    "               activation=activation_func, \n",
    "               return_sequences=True, \n",
    "               input_shape=(n_in, n_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eac19ea-9987-41ad-b5ca-a132b91ae7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add hidden layers\n",
    "add_hidden_layers(n_layers=1, \n",
    "                  n_nodes=30, \n",
    "                  activation=activation_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3453ed-2bb3-4c37-a4af-6411bd0308e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add final Hidden layer\n",
    "model.add(LSTM(60, activation=activation_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a925fd-82a7-4f55-aa50-9dfb1302c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add output layer\n",
    "model.add(Dense(n_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5016c99e-b2bb-4c8e-9d9b-7a5aac724fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ca5932-acc5-4e27-88a4-50a6484fc088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326fdab6-23df-4cb3-992a-cf29a631823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and train the model\n",
    "res = model.fit(X, y, epochs=50, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78073973-b420-4ff5-adc1-fee989ab555c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4d87e8-df11-4ebc-bca4-1fd1e417c8c3",
   "metadata": {},
   "source": [
    "### *Visualize Training Results*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac06b20-a1ec-45d6-9b73-8e4be77af1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training_results(res, model_loss_filename=\"model_loss_KO.png\", model_accuracy_filename=\"model_accuracy_KO.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d16fd-664c-49e3-affe-9155258d1dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training_price(filename=\"pred_prices_KO.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e030b8b-0421-4eef-9d32-89b325eef53b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04e1c06-3ab2-4d24-b882-82cbfe0b3772",
   "metadata": {},
   "source": [
    "### *Save model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be757c-2265-443c-9a4b-16a3b7a35770",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../ml/savedmodels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575d73f5-dadb-43a7-bda4-bce3a834cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"proj2_demo_model_KO.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c1bf0a-6367-4f69-a0ea-cf9c3537a1a1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf4e5ab-07ae-45d9-af3c-c8252c394426",
   "metadata": {},
   "source": [
    "## Forecasting future stock price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6164a8-e456-47e3-8cc4-22a2bc72e574",
   "metadata": {},
   "source": [
    "### *Get market data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae90902-93ab-4547-8504-48fac1d9977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set market data date range \n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "pred_end_date  = datetime.now()\n",
    "pred_start_date  = (pred_end_date - timedelta(days=200))\n",
    "\n",
    "pred_start_date = pred_start_date.strftime('%Y-%m-%d')\n",
    "pred_end_date = pred_end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"Forecast start date : {pred_start_date}\")\n",
    "print(f\"Forecast end date : {pred_end_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b8438-97da-49da-bcc3-de75039cada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "pred_ohlcv_df = alpaca.ohlcv(test_tickers, start_date=pred_start_date, end_date=pred_end_date)\n",
    "\n",
    "pred_tech_ind = technicals.TechnicalAnalysis(pred_ohlcv_df)\n",
    "\n",
    "pred_df = pred_tech_ind.get_all_technicals(test_tickers[0])\n",
    "\n",
    "pred_df.drop(columns=['open', 'high', 'low', 'volume'], inplace=True)\n",
    "\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d52ed35-94f1-46ae-aacc-7c147f825d65",
   "metadata": {},
   "source": [
    "### *Data pre-processing : Scaling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0aeba8-2fe7-4be6-bafe-e67b1caca76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_scaler = RobustScaler()\n",
    "transformed_pred_df = pd.DataFrame(pred_scaler.fit_transform(pred_df), \n",
    "                       columns=pred_df.columns, \n",
    "                       index=pred_df.index).tail(n_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7542c8-38f6-4cf7-a3c7-18855432110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c907fce1-7753-40ad-aef5-a85ef325478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform technical analysis data to np.array\n",
    "pred_arr = np.array(transformed_pred_df).reshape(1, n_in, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1ebc7a-c57a-4a5b-968d-f52afcf10c31",
   "metadata": {},
   "source": [
    "### *Forecast stock price*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc728d0d-1dff-48d2-8474-95655ab926e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "from tensorflow.keras.models import load_model\n",
    "forecast_model = load_model(\"proj2_demo_model_KO.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9294579d-b33a-4ff4-8e63-08a84f205f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting off of the new data\n",
    "pred_y = forecast_model.predict(pred_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83acd2f-45eb-46ca-a3f3-2b2327c008f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse_transform the predicted values back to original scale\n",
    "pred_y = close_scaler.inverse_transform(pred_y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc92d3f4-0136-43d1-8435-7d9f546cf995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse perdicted values to pd.DataFrame, adjust date scale (index)\n",
    "preds = pd.DataFrame(pred_y, \n",
    "                     index=pd.date_range(start=df.index[-1]+timedelta(days=1), \n",
    "                                         periods=len(pred_y), \n",
    "                                         freq=\"B\"), \n",
    "                     columns=[df.columns[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a120b39-74f4-4a64-a7fc-ec83c63087bf",
   "metadata": {},
   "source": [
    "### *Plot the results*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4418623-c32c-4f66-aa8d-6e749a699456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get actual historical prices\n",
    "actual = pred_df[[\"close\"]].tail(n_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca5ae7d-cc27-4ea8-b8bd-27daef692566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get company name from ticker\n",
    "# Source: https://stackoverflow.com/questions/38967533/retrieve-company-name-with-ticker-symbol-input-yahoo-or-google-api\n",
    "import requests\n",
    "\n",
    "def get_company_name(ticker):\n",
    "    url = \"http://d.yimg.com/autoc.finance.yahoo.com/autoc?query={}&region=1&lang=en\".format(ticker)\n",
    "\n",
    "    result = requests.get(url).json()\n",
    "\n",
    "    for x in result['ResultSet']['Result']:\n",
    "        if x['symbol'] == ticker:\n",
    "            return x['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78862291-2202-44de-83d1-ea38d1cc2bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(actual, label=\"Actual Prices\")\n",
    "plt.plot(preds, label=\"Predicted Prices\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.xlabel(\"Dates\")\n",
    "plt.title(f\"Forecasting next {len(pred_y)} days for {get_company_name(test_tickers[0])}\")\n",
    "plt.legend()\n",
    "plt.savefig(\"model_forecast_KO.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42420ef-6a06-46e5-ae9a-8cf9892cb3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
